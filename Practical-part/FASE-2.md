# ğŸš€ FASE 2: InstalaciÃ³n del clÃºster Kubernetes con kubeadm

### ğŸ”° IntroducciÃ³n
En esta segunda fase del proyecto, se procederÃ¡ a la instalaciÃ³n y configuraciÃ³n bÃ¡sica de un clÃºster Kubernetes sobre las mÃ¡quinas virtuales previamente creadas en Proxmox. Se utilizarÃ¡ kubeadm, una herramienta oficial que facilita la inicializaciÃ³n del clÃºster de forma segura y reproducible.

Durante esta fase, se instalarÃ¡n los componentes principales en el nodo maestro y se unirÃ¡n los nodos trabajadores al clÃºster, estableciendo la base para el despliegue de aplicaciones en fases posteriores.

## 1. Requisitos previos en todas las mÃ¡quinas.
Antes de instalar Kubernetes, se deben cumplir ciertos requisitos en todos los nodos (master y workers).

### ğŸ§© Desactivar swap:
```
sudo swapoff -a
sudo sed -i '/ swap / s/^/#/' /etc/fstab
```

### ğŸ”§ Cargar mÃ³dulos del kernel necesarios:
```
echo 'br_netfilter' | sudo tee /etc/modules-load.d/k8s.conf
```

### ğŸ”§ Ajustes de red:
```
echo 'net.bridge.bridge-nf-call-ip6tables = 1' | sudo tee -a /etc/sysctl.d/k8s.conf
echo 'net.bridge.bridge-nf-call-iptables = 1' | sudo tee -a /etc/sysctl.d/k8s.conf
sudo sysctl --system
```

## 2. InstalaciÃ³n de Docker o containerd.
Kubernetes necesita un runtime de contenedores. En este caso utilizaremos containerd.

### ğŸ³ Instalar containerd:
```
sudo apt update && sudo apt install -y containerd
```

### ğŸ”§ Configurar containerd:
```
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
sudo systemctl restart containerd
sudo systemctl enable containerd
```

## 3. InstalaciÃ³n de kubeadm, kubelet y kubectl.
### ğŸ§ª Comandos de instalaciÃ³n:
```
sudo apt update && sudo apt install -y apt-transport-https ca-certificates curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```

## 4. InicializaciÃ³n del nodo master.
Este paso se realiza solo en el nodo master para inicializar el clÃºster Kubernetes.

### âš™ï¸ Ejecutar:
```
sudo kubeadm init --pod-network-cidr=192.168.0.0/16
```
### ğŸ‘¤ Configurar el acceso como usuario normal:
```
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

## 5. InstalaciÃ³n del complemento de red (CNI) desde el nodo master.
Kubernetes necesita un complemento de red para la comunicaciÃ³n entre pods. Este paso se realiza desde el nodo master, una vez configurado el acceso a kubectl.

### ğŸŒ Instalar Calico:
```
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml
```

## 6. UniÃ³n de nodos workers al clÃºster.
Este paso se realiza en cada nodo worker para que se unan al clÃºster ya creado.

### ğŸ‘‡ Ejecutar el comando proporcionado tras la inicializaciÃ³n del master:
```
sudo kubeadm join 192.168.1.100:6443 --token abcdef.0123456789abcdef \
    --discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

---

### âœ… Resultado final de la Fase 2.
Tras finalizar esta fase:
- Se ha creado un clÃºster Kubernetes funcional con un nodo maestro y uno o mÃ¡s nodos trabajadores.
- Se ha instalado un complemento de red (Calico) para la comunicaciÃ³n entre pods.
- Todos los nodos estÃ¡n correctamente conectados y sincronizados.
- El entorno estÃ¡ listo para desplegar aplicaciones y aÃ±adir funcionalidades como monitorizaciÃ³n o CI/CD en las siguientes fases.

